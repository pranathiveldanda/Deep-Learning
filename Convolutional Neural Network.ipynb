{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d27fce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vsonu\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:79: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.298\n",
      "[1,   400] loss: 2.282\n",
      "[1,   600] loss: 2.210\n",
      "[2,   200] loss: 1.973\n",
      "[2,   400] loss: 1.887\n",
      "[2,   600] loss: 1.834\n",
      "[3,   200] loss: 1.707\n",
      "[3,   400] loss: 1.663\n",
      "[3,   600] loss: 1.614\n",
      "[4,   200] loss: 1.540\n",
      "[4,   400] loss: 1.513\n",
      "[4,   600] loss: 1.502\n",
      "[5,   200] loss: 1.446\n",
      "[5,   400] loss: 1.437\n",
      "[5,   600] loss: 1.407\n",
      "[6,   200] loss: 1.369\n",
      "[6,   400] loss: 1.330\n",
      "[6,   600] loss: 1.347\n",
      "[7,   200] loss: 1.290\n",
      "[7,   400] loss: 1.294\n",
      "[7,   600] loss: 1.263\n",
      "[8,   200] loss: 1.217\n",
      "[8,   400] loss: 1.214\n",
      "[8,   600] loss: 1.207\n",
      "[9,   200] loss: 1.159\n",
      "[9,   400] loss: 1.153\n",
      "[9,   600] loss: 1.139\n",
      "[10,   200] loss: 1.099\n",
      "[10,   400] loss: 1.106\n",
      "[10,   600] loss: 1.075\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3afc43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 1.826\n",
      "[1,   400] loss: 1.478\n",
      "[1,   600] loss: 1.339\n",
      "[2,   200] loss: 1.145\n",
      "[2,   400] loss: 1.104\n",
      "[2,   600] loss: 1.062\n",
      "[3,   200] loss: 0.969\n",
      "[3,   400] loss: 0.967\n",
      "[3,   600] loss: 0.941\n",
      "[4,   200] loss: 0.856\n",
      "[4,   400] loss: 0.848\n",
      "[4,   600] loss: 0.863\n",
      "[5,   200] loss: 0.790\n",
      "[5,   400] loss: 0.782\n",
      "[5,   600] loss: 0.789\n",
      "[6,   200] loss: 0.720\n",
      "[6,   400] loss: 0.732\n",
      "[6,   600] loss: 0.716\n",
      "[7,   200] loss: 0.660\n",
      "[7,   400] loss: 0.665\n",
      "[7,   600] loss: 0.672\n",
      "[8,   200] loss: 0.599\n",
      "[8,   400] loss: 0.617\n",
      "[8,   600] loss: 0.626\n",
      "[9,   200] loss: 0.571\n",
      "[9,   400] loss: 0.566\n",
      "[9,   600] loss: 0.570\n",
      "[10,   200] loss: 0.523\n",
      "[10,   400] loss: 0.523\n",
      "[10,   600] loss: 0.539\n",
      "Finished Training\n",
      "Accuracy of the network with batch normalization and regulazization: 69 %\n"
     ]
    }
   ],
   "source": [
    "#Incorporating Batch Normalization and regularization loss to the model to improve its performance\n",
    "\n",
    "\n",
    "class CNN_batchnorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_batchnorm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def reg(model, reg_strength):\n",
    "    reg_loss = 0\n",
    "    for param in model.parameters():\n",
    "        reg_loss += torch.norm(param, p=2)  \n",
    "    return reg_strength * reg_loss\n",
    "\n",
    "CNN_batch = CNN_batchnorm()\n",
    "\n",
    "optimizer_batch = optim.SGD(CNN_batch.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "reg_strength = 0.001\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer_batch.zero_grad()\n",
    "        outputs = CNN_batch(inputs)\n",
    "        reg_loss = reg(CNN_batch,reg_strength)\n",
    "        loss = criterion(outputs, labels) + reg_loss\n",
    "        loss.backward()\n",
    "        optimizer_batch.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = CNN_batch(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network with batch normalization and regulazization: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
